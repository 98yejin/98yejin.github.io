<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <title>My site</title>
    <link
      rel="stylesheet"
      href="/static/css/styles.css"
    />
  </head>

  <body>
    <div class="page-container">
      <header>
  <div class="header-content">
    <div class="container">
      <h1 class="logo">
        <a href="/" class="heading-link">YEJIN PARK</a>
      </h1>
    </div>
    <nav>
      <ul>
        <li><a href="/">Home</a></li>
        <li><a href="/career">Career</a></li>
        <li><a href="/education">Education</a></li>
        <li><a href="/contact">Contact</a></li>
      </ul>
    </nav>
  </div>
</header>

      <main>
<h1>ESTsecurity</h1>
<h2>Summary</h2>

<ul>
<li>July 2020 ~ February 2021</li>
<li>PMS-MPI Cell (Internship)</li>
<li>Python Crawler Optimization
<ul>
<li>Reduced collection time by over 80%, from 3 hours to under 30 minutes</li>
</ul></li>
<li>Automation of Manual Data Entry
<ul>
<li>Decreased the time required for this task from over an hour to less than 10 minutes</li>
</ul></li>
<li>News Crawler and Report Generation
<ul>
<li>Automated the process of filtering news related to the team's products</li>
</ul></li>
</ul>

<h2>Details</h2>

<h3>Python Crawler Optimization</h3>

<ul>
<li>Optimized a Python crawler that initially relied entirely on Selenium, resulting in slow performance and frequent failures (over 50% error rate) without any error handling or notifications</li>
<li>Refactored parts of the crawler using Scrapy to improve speed and implemented an alerting system</li>
<li>Enhanced data collection methods and timing by incorporating server maintenance information and server-provided data</li>
<li>Reduced collection time by over 80%, from 3 hours to under 30 minutes</li>
</ul>

<h3>Automation of Manual Data Entry</h3>

<ul>
<li>Automated the manual entry of version information files, which was a repetitive task prone to errors due to its high volume</li>
<li>Decreased the time required for this task from over an hour to less than 10 minutes, significantly improving efficiency and requiring only a final review</li>
</ul>

<h3>News Crawler and Report Generation</h3>

<ul>
<li>Managed a news crawler that collected 100-200 news articles daily</li>
<li>Automated the process of filtering news related to the team's products by:
<ul>
<li>Collecting frequently used keywords from the titles of previously accumulated product-related news (updated periodically using a script)</li>
<li>Generating reports based on these keywords, eliminating the need for manual separation of relevant news</li>
</ul></li>
</ul>

<div class="align-right">
  <a href="/" class="move">Back Home</a>
</div>
</main>

      <footer>&copy; 2024 Yejin Park. All rights reserved.</footer>
    </div>
  </body>
</html>